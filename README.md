# EfficientDM Toy Example
A step-by-step implementation of EfficientDM (Efficient Quantization-Aware Fine-Tuning of Low-Bit Diffusion Models) concepts on MNIST dataset.

# ğŸ“– Overview
This repository provides a educational implementation of the key concepts from the paper <ins>"EfficientDM: Efficient Quantization-Aware Fine-Tuning of Low-Bit Diffusion Models" (ICLR 2024)</ins>. While the original paper focuses on diffusion models, this implementation demonstrates the core techniques using a simpler MNIST classification task for clarity and accessibility.

# ğŸ¯ Key Concepts Implemented

- <ins>QALoRA (Quantization-Aware Low-Rank Adaptation)</ins>: Merging LoRA weights with model weights before quantization
- <ins>Scale-Aware Optimization</ins>: Addressing ineffective learning due to varying quantization scales
- <ins>TALSQ (Temporal Activation LSQ)</ins>: Learned step-size quantization for activations
- <ins>Knowledge Distillation</ins>: Transferring knowledge from FP32 to quantized models
- <ins>Data-Free Fine-Tuning</ins>: Training without access to original dataset

# ğŸ“‚Project Structure
```
efficientdm_toy/
â”œâ”€â”€ config.py                    # Common configuration
â”œâ”€â”€ utils.py                      # Utility functions
â”œâ”€â”€ step1_baseline_model.py      # Train FP32 baseline
â”œâ”€â”€ step2_quantization_basics.py # Basic PTQ implementation
â”œâ”€â”€ step3_qalora_layer.py        # QALoRA implementation
â”œâ”€â”€ step4_scale_aware_training.py # Scale-aware optimization
â”œâ”€â”€ step5_talsq_temporal.py      # TALSQ implementation
â”œâ”€â”€ step6_knowledge_distillation.py # Knowledge distillation
â”œâ”€â”€ step7_full_integration.py    # Final evaluation
â”œâ”€â”€ checkpoints/                 # Saved models
â””â”€â”€ data/                        # MNIST dataset
```

# ğŸš€ Getting Started
## Prerequisites
```
pip install torch torchvision numpy matplotlib
```

## Running the Complete Pipeline
- Execute each step sequentially:
```
# Step 1: Train baseline FP32 model (~98% accuracy)
python step1_baseline_model.py

# Step 2: Apply basic quantization (demonstrates performance degradation)
python step2_quantization_basics.py

# Step 3: Implement QALoRA (recover performance with LoRA)
python step3_qalora_layer.py

# Step 4: Add scale-aware optimization (further improvement)
python step4_scale_aware_training.py

# Step 5: Implement TALSQ (temporal activation scales)
python step5_talsq_temporal.py

# Step 6: Apply knowledge distillation (maximize recovery)
python step6_knowledge_distillation.py

# Step 7: Final evaluation and comparison
python step7_full_integration.py
```

# ğŸ“ License
MIT License - This is an educational implementation for learning purposes.

# ğŸ™ Acknowledgments
- Original EfficientDM paper authors
- PyTorch team for the framework
- MNIST dataset creators

